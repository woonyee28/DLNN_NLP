{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO: Maybe try this - https://youtu.be/0VLAoVGf_74?si=zuJ8AL_wLbsbRdd5\n",
    "Compare MHA, MQA, MLA (DeepSeek)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Apply TransformerClassifier (Encoder Only) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_utils import *\n",
    "from datasets import load_dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformer import TransformerClassifierMHA\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torch.optim.lr_scheduler import OneCycleLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Prepare Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 28000\n",
      "Validation size: 4000\n",
      "Test size: 8000\n"
     ]
    }
   ],
   "source": [
    "crowd_dataset = load_dataset(\"csv\", data_files=\"./dataset/text_emotion.csv\")\n",
    "crowd_dataset = crowd_dataset.rename_column('content', 'text')\n",
    "crowd_dataset_dict = create_train_validation_test(crowd_dataset['train'])\n",
    "\n",
    "embedding_matrix = np.load(EMBEDDING_PATH)\n",
    "\n",
    "with open(WORD2IDX_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    word2idx = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentiment classes: 13\n",
      "Emotion classes: ['anger' 'boredom' 'empty' 'enthusiasm' 'fun' 'happiness' 'hate' 'love'\n",
      " 'neutral' 'relief' 'sadness' 'surprise' 'worry']\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(crowd_dataset_dict['train']['sentiment'])\n",
    "val_labels = label_encoder.transform(crowd_dataset_dict['validation']['sentiment'])\n",
    "test_labels = label_encoder.transform(crowd_dataset_dict['test']['sentiment'])\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(f\"Number of sentiment classes: {num_classes}\")\n",
    "print(f\"Emotion classes: {label_encoder.classes_}\")\n",
    "\n",
    "crowd_labels_dict = {\n",
    "    'train': train_labels,\n",
    "    'validation': val_labels,\n",
    "    'test': test_labels\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created DataLoaders with 875 training batches, 125 validation batches, and 250 test batches.\n"
     ]
    }
   ],
   "source": [
    "crowd_dataloaders_dict = create_dataloaders(crowd_dataset_dict, crowd_labels_dict, word2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Train the TransformerClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "TransformerClassifier_MHA = TransformerClassifierMHA(len(word2idx), 13, 100, 5, 3, 200, 100, 0.1)  \n",
    "# vocab_size, num_classes, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "TransformerClassifier_MHA.to(device)\n",
    "\n",
    "embedding_matrix_tensor = torch.FloatTensor(embedding_matrix)\n",
    "TransformerClassifier_MHA.embedding.weight.data.copy_(embedding_matrix_tensor)\n",
    "TransformerClassifier_MHA.embedding.weight.requires_grad = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(TransformerClassifier_MHA.parameters(), lr=0.001)\n",
    "\n",
    "total_steps = 100 * len(crowd_dataloaders_dict['train'])\n",
    "scheduler = OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=0.001,\n",
    "    total_steps=total_steps,\n",
    "    pct_start=0.1,      \n",
    "    anneal_strategy='cos'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs=100):\n",
    "    since = time.time()\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_val_f1 = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "        \n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                model.train()  \n",
    "            else:\n",
    "                model.eval()  \n",
    "                \n",
    "            running_loss = 0.0\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        scheduler.step()\n",
    "                \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "            epoch_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "            \n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} F1: {epoch_f1:.4f}')\n",
    "            \n",
    "            if phase == 'validation':\n",
    "                if epoch_f1 > best_val_f1:\n",
    "                    best_val_f1 = epoch_f1\n",
    "                    best_model_wts = model.state_dict().copy()\n",
    "                    \n",
    "                    torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'val_f1': epoch_f1,\n",
    "                    }, 'best_transformer_MHA_model.pt')\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val F1: {best_val_f1:.4f}')\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "trained_model = train_model(TransformerClassifier_MHA, crowd_dataloaders_dict, criterion, optimizer, scheduler, num_epochs=100)\n",
    "\n",
    "def evaluate_model(model, test_dataloader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    test_acc = accuracy_score(all_labels, all_preds)\n",
    "    test_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    print(f'Test Accuracy: {test_acc:.4f}')\n",
    "    print(f'Test F1 Score: {test_f1:.4f}')\n",
    "    \n",
    "    return test_acc, test_f1\n",
    "\n",
    "test_acc, test_f1 = evaluate_model(trained_model, crowd_dataloaders_dict['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
